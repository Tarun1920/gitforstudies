{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdb933-bee7-4916-985a-3ddb6dda76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5d309-8907-401e-86b8-8fd093bf8993",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among two or more groups. To use ANOVA effectively, several assumptions must be met. Violations of these assumptions can impact the validity of the results. Here are the key assumptions and examples of potential violations:\n",
    "\n",
    "1. Independence: The observations within and between groups should be independent of each other. Violations could occur in cases like repeated measurements on the same subjects or if data points are somehow related.\n",
    "\n",
    "2. Normality: The data within each group should be normally distributed. Violations can occur when the data is heavily skewed or exhibits non-normal distributions. For example, if you have a small sample size or outliers, normality assumptions can be violated.\n",
    "\n",
    "3. Homogeneity of Variance (Homoscedasticity): The variances of the groups should be approximately equal. Violations could lead to unequal variances among the groups, which can affect the overall F-statistic. This assumption can be violated if one group has significantly more variability than the others.\n",
    "\n",
    "4. Independence of Observations: The observations should be independent of each other. Violations occur when data points are not independent, such as when you have repeated measures within the same subject or data collected over time without considering autocorrelation.\n",
    "\n",
    "Examples of Violations:\n",
    "\n",
    "Non-Normal Data: If your data is not normally distributed, ANOVA may not provide accurate results. For instance, if you're comparing the test scores of students in a large class, and the scores are skewed because of a few high-achieving students, the normality assumption may be violated.\n",
    "\n",
    "Unequal Variances: If you're comparing the yields of different crops in various regions, and one region has significantly higher variability in crop yield compared to the others, the homogeneity of variance assumption may be violated.\n",
    "\n",
    "Non-Independence: Suppose you are comparing the effectiveness of two different drugs on the same set of patients, and the measurements taken from the same patient are not independent. This violates the independence assumption.\n",
    "\n",
    "Outliers: Outliers in your data can skew the results and violate assumptions. For example, if you're comparing the income levels of households in different neighborhoods, and there's an outlier with an extremely high income in one neighborhood, this can affect the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3e0ff-978e-4cdc-9cab-eb70685203cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b228f-762f-4038-93c9-b65106b7a2a6",
   "metadata": {},
   "source": [
    "One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when you have one categorical independent variable with more than two levels (groups), and you want to determine if there are statistically significant differences in the means of a continuous dependent variable between these groups.\n",
    "Example: You want to compare the average test scores of students who studied under three different teaching methods (Method A, Method B, Method C) to see if one teaching method leads to significantly different scores.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when you have two independent categorical variables, and you want to understand their individual and interactive effects on a continuous dependent variable. It's used to examine whether there are main effects for each independent variable and whether there is an interaction effect between them.\n",
    "Example: You want to investigate the effects of both teaching methods (Method A, Method B, Method C) and gender (Male, Female) on students' test scores. You want to determine if there are main effects of teaching method and gender and if there is an interaction effect between them.\n",
    "Repeated Measures ANOVA (Within-Subjects ANOVA):\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have a within-subjects or repeated measures design. This means that the same subjects are measured under multiple conditions or at different time points. It's used to analyze whether there are significant differences in the means of a continuous dependent variable over time or under different conditions.\n",
    "Example: You are conducting a study to measure the effect of a drug on blood pressure, and you measure the blood pressure of the same group of individuals before taking the drug, immediately after taking the drug, and 1 hour after taking the drug. Repeated Measures ANOVA is used to analyze whether there are significant changes in blood pressure over these time points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54be57-2a72-42ce-bde4-9a7956d99dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e24ed-3602-4bd5-837a-d1b9e8d9594d",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps explain how the total variability in the data is divided into different sources to assess the significance of group differences. \n",
    "Total Variance (Total Sum of Squares, SST): This represents the overall variability in the data, regardless of group membership. It's calculated as the sum of the squared differences between each data point and the grand mean of all the data.\n",
    "\n",
    "Between-Group Variance (Between-Groups Sum of Squares, SSB): This component measures the variation among the group means. It quantifies the differences between the group means and the overall grand mean. It represents the portion of the total variance that can be attributed to the effect of the independent variable.\n",
    "\n",
    "Within-Group Variance (Within-Groups Sum of Squares, SSW): This component accounts for the variability within each group. It is the sum of squared differences between individual data points and their respective group means. It reflects the random or unexplained variability within groups.\n",
    "\n",
    "The partitioning of variance is crucial for several reasons:\n",
    "\n",
    "Hypothesis Testing: ANOVA is used to test whether there are statistically significant differences among the group means. Partitioning the variance helps to calculate the F-statistic, which is used to determine whether the between-group variance is significantly larger than the within-group variance. This informs whether the independent variable has a significant effect on the dependent variable.\n",
    "\n",
    "Effect Size: By understanding how much of the total variance is due to the effect of the independent variable (SSB), researchers can assess the practical significance or effect size of the treatment or condition being studied. A larger SSB relative to SST indicates a stronger effect.\n",
    "\n",
    "Post-Hoc Analysis: After finding that there is a significant effect in ANOVA, post-hoc tests like Tukey's HSD or Bonferroni tests can be used to determine which specific groups differ significantly from each other. Partitioning of variance helps identify where these differences occur.\n",
    "\n",
    "Interpretation: It provides a clear breakdown of the sources of variability in the data, helping researchers understand the contributions of the independent variable and unexplained variance within groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26848832-97c6-411f-b62c-30c9f08dc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6413b42e-fe2a-4c3c-af32-a73405d939d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 532.9333333333334\n",
      "Explained Sum of Squares (SSE): 484.93333333333345\n",
      "Residual Sum of Squares (SSR): 47.99999999999994\n",
      "F-statistic: 60.61666666666651\n",
      "P-value: 5.33838774723333e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = np.array([12, 15, 14, 17, 13])\n",
    "group2 = np.array([23, 27, 22, 21, 25])\n",
    "group3 = np.array([8, 9, 10, 12, 11])\n",
    "\n",
    "# Combine the data from all groups\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the grand mean\n",
    "grand_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - grand_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (mean_group1 - grand_mean) ** 2 + \\\n",
    "      len(group2) * (mean_group2 - grand_mean) ** 2 + \\\n",
    "      len(group3) * (mean_group3 - grand_mean) ** 2\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Perform one-way ANOVA to confirm the results\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc32251-b8cb-44aa-9260-e82066386cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233aade-d42d-4c43-8139-ddacf6bc34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas DataFrame with your data\n",
    "data = pd.DataFrame({\n",
    "    'Factor1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Factor2': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'DependentVariable': [10, 12, 14, 15, 16, 17, 8, 10, 9]\n",
    "})\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "model = ols('DependentVariable ~ Factor1 * Factor2', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_Factor1 = anova_table.loc['Factor1', 'F']\n",
    "main_effect_Factor2 = anova_table.loc['Factor2', 'F']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'F']\n",
    "\n",
    "print(\"Main Effect of Factor1:\", main_effect_Factor1)\n",
    "print(\"Main Effect of Factor2:\", main_effect_Factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bf06e-f438-4cd6-b06d-0b22f8b8f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653456f-5bd0-4b88-9c2b-7fb82e513a56",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic and the associated p-value are used to assess whether there are statistically significant differences among the means of the groups. In your scenario:\n",
    "\n",
    "F-statistic: 5.23\n",
    "p-value: 0.02\n",
    "To interpret these results, you can follow these steps:\n",
    "\n",
    "Null Hypothesis (H0): Start by stating the null hypothesis. In a one-way ANOVA, the null hypothesis is that there are no significant differences among the group means. Mathematically, it's represented as:\n",
    "\n",
    "H0: μ1 = μ2 = μ3 = ... = μk (where k is the number of groups)\n",
    "\n",
    "This means that all group means are equal.\n",
    "\n",
    "Alternative Hypothesis (Ha): The alternative hypothesis, also known as the research hypothesis, is the opposite of the null hypothesis. In your case, it's that at least one group mean is different from the others:\n",
    "\n",
    "Ha: At least one μi is different from the rest\n",
    "\n",
    "This suggests that there is a significant difference among the group means.\n",
    "\n",
    "Interpreting the p-value: The p-value represents the probability of obtaining an F-statistic as extreme as the one observed if the null hypothesis is true. In your case, the p-value is 0.02.\n",
    "\n",
    "If p-value ≤ α (usually 0.05), you reject the null hypothesis.\n",
    "If p-value > α, you fail to reject the null hypothesis.\n",
    "Conclusion:\n",
    "\n",
    "With a p-value of 0.02, which is less than the commonly chosen significance level of 0.05 (α), you would reject the null hypothesis.\n",
    "Practical Interpretation: You can conclude that there is evidence to suggest that at least one group mean is different from the others. In other words, there are statistically significant differences among the groups.\n",
    "\n",
    "Post-Hoc Analysis: After rejecting the null hypothesis, you might want to conduct post-hoc tests (e.g., Tukey's HSD or Bonferroni) to determine which specific groups are different from each other.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you would conclude that there are statistically significant differences among the groups, suggesting that at least one group mean is different from the others. This result indicates that the independent variable (the factor being studied) has a significant effect on the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3548a6-ce5f-4209-b91d-35d6c3de2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15180297-bd0b-49ee-b5db-3bef31d18a8f",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is important for maintaining the integrity of your analysis and ensuring valid results. There are several methods to deal with missing data, each with its own potential consequences. Here are some common approaches and their implications:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Method: You exclude cases with any missing data from the analysis, analyzing only the cases with complete data.\n",
    "Consequences:\n",
    "Pros: Simple and straightforward.\n",
    "Cons: Reduces sample size, which can lead to reduced statistical power and less representative results. The assumption that data is missing completely at random (MCAR) is strict and often unrealistic.\n",
    "Pairwise Deletion (Available Case Analysis):\n",
    "\n",
    "Method: You analyze all available data for each pair of measurements, using all cases that have data for that specific comparison.\n",
    "Consequences:\n",
    "Pros: Maximizes the use of available data.\n",
    "Cons: May lead to different sample sizes for different comparisons, making it challenging to interpret results. It assumes that data are missing at random (MAR), which is more flexible but still requires assumptions.\n",
    "Imputation Techniques:\n",
    "\n",
    "Methods: Impute missing values using various techniques, such as mean imputation, median imputation, regression imputation, or multiple imputation.\n",
    "Consequences:\n",
    "Pros: Preserves sample size and can be more robust. Helps to account for uncertainty due to missing data.\n",
    "Cons: The choice of imputation method can impact results. Imputation assumes that missing data can be predicted or replaced, which may not always be true.\n",
    "Mixed-Effects Models (Longitudinal Models):\n",
    "\n",
    "Method: Analyze the data using mixed-effects models that account for the correlation structure within subjects and handle missing data through maximum likelihood estimation.\n",
    "Consequences:\n",
    "Pros: Utilizes all available data, accounts for within-subject correlation, and does not require imputation.\n",
    "Cons: More complex to implement and interpret. Requires knowledge of mixed-effects modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f4470-7016-4f18-9259-6ba060800777",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a1084-7ed3-409f-831f-d6884b87346b",
   "metadata": {},
   "source": [
    "After conducting an analysis of variance (ANOVA) and finding a significant difference among groups, post-hoc tests are used to determine which specific groups differ from each other. There are several common post-hoc tests, and the choice of which one to use depends on the research question and the design of the study.\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "Use: Tukey's HSD is used when you have conducted a one-way ANOVA to compare means across multiple groups. It is appropriate when you want to test all possible pairwise group differences.\n",
    "Example: Suppose you conducted a one-way ANOVA to compare the effectiveness of four different drug treatments. Tukey's HSD would help you determine which specific drug treatments are significantly different from each other.\n",
    "Bonferroni Correction:\n",
    "\n",
    "Use: The Bonferroni correction is a conservative method used when you want to control the familywise error rate (the probability of making at least one Type I error). It's suitable for situations where you have multiple pairwise comparisons.\n",
    "Example: In a clinical trial, you are comparing the efficacy of a new drug to a placebo and two existing medications. The Bonferroni correction can be used to adjust the alpha level to control for the increased risk of Type I errors when conducting multiple comparisons.\n",
    "Sidak Correction:\n",
    "\n",
    "Use: Similar to Bonferroni, the Sidak correction is used to control the familywise error rate, but it is less conservative than Bonferroni. It's a good choice when you have multiple comparisons to make.\n",
    "Example: In a marketing study, you want to determine if there are differences in customer satisfaction between five different product variants. The Sidak correction can help you control the Type I error rate when conducting multiple pairwise comparisons.\n",
    "Dunnett's Test:\n",
    "\n",
    "Use: Dunnett's test is used when you have a control group and you want to compare each treatment group to the control group, while controlling for familywise error.\n",
    "Example: In a study evaluating the effects of various training programs on employee productivity, you want to compare each training program to the no-training control group. Dunnett's test would help you determine which training programs significantly differ from the control group.\n",
    "Holm-Bonferroni Method:\n",
    "\n",
    "Use: The Holm-Bonferroni method is a compromise between Tukey's HSD and Bonferroni correction. It is used to control familywise error while being less conservative than Bonferroni.\n",
    "Example: In a consumer preference study, you want to compare the ratings of multiple products to identify which ones are significantly preferred by customers. The Holm-Bonferroni method can help you make these comparisons while controlling for Type I errors.\n",
    "Games-Howell Test:\n",
    "\n",
    "Use: The Games-Howell test is a non-parametric post-hoc test used when the assumption of homogeneity of variances is violated, making Tukey's HSD or Bonferroni inappropriate.\n",
    "Example: In an experiment comparing the test scores of students under different teaching methods, you find that the variances are not equal. The Games-Howell test can be used to compare specific pairs of teaching methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148d7b5-2510-47ac-bdce-57fe90269d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05051c48-0bd1-431a-9fc6-b3e27b464d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one-way ANOVA is statistically significant.\n",
      "F-statistic: 83.80637982195852\n",
      "p-value: 1.590786862669165e-19\n",
      "There is at least one statistically significant difference between the diet groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for three diet groups (A, B, and C)\n",
    "diet_a = [2.5, 3.1, 3.6, 2.7, 3.2, 3.8, 2.9, 2.8, 3.4, 3.0, 3.5, 3.2, 2.6, 3.0, 2.7, 3.1, 3.3, 3.5, 2.9, 3.4, 3.0, 3.2, 3.1, 2.8, 3.3]\n",
    "diet_b = [2.4, 2.6, 2.8, 2.3, 2.9, 3.1, 2.5, 2.7, 2.6, 2.4, 2.9, 2.8, 2.7, 2.8, 2.6, 2.7, 2.5, 2.8, 2.9, 2.7, 2.5, 2.6, 2.8, 2.4, 2.9]\n",
    "diet_c = [2.0, 1.8, 2.2, 2.1, 2.3, 2.5, 2.2, 2.0, 2.3, 2.4, 2.1, 2.0, 2.2, 2.1, 2.4, 2.5, 2.3, 2.2, 2.1, 2.5, 2.0, 2.3, 2.2, 2.1, 2.4]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is at least one statistically significant difference between the diet groups.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is no statistically significant difference between the diet groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152bb60a-64a5-4ad2-bb57-02cb4def2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4326bf9-bb9a-4334-aa6e-f298737c6251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Software is not statistically significant.\n",
      "Main Effect of Experience is not statistically significant.\n",
      "Interaction Effect is not statistically significant.\n",
      "F-statistic for Software: 8.339805825242733\n",
      "F-statistic for Experience: 7.077669902912674\n",
      "F-statistic for Interaction: 40.980582524271846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas DataFrame with your data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'B', 'C'] * 10,\n",
    "    'Experience': ['Novice', 'Experienced'] * 15,\n",
    "    'Time': [20, 25, 22, 28, 30, 29, 18, 21, 23, 27, 26, 24, 19, 22, 20, 27, 31, 30, 19, 21, 25, 23, 29, 28, 20, 24, 22, 26, 31, 27]\n",
    "})\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "model = ols('Time ~ Software * Experience', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_Software = anova_table.loc['Software', 'F']\n",
    "main_effect_Experience = anova_table.loc['Experience', 'F']\n",
    "interaction_effect = anova_table.loc['Software:Experience', 'F']\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if main_effect_Software < alpha:\n",
    "    print(\"Main Effect of Software is statistically significant.\")\n",
    "else:\n",
    "    print(\"Main Effect of Software is not statistically significant.\")\n",
    "\n",
    "if main_effect_Experience < alpha:\n",
    "    print(\"Main Effect of Experience is statistically significant.\")\n",
    "else:\n",
    "    print(\"Main Effect of Experience is not statistically significant.\")\n",
    "\n",
    "if interaction_effect < alpha:\n",
    "    print(\"Interaction Effect is statistically significant.\")\n",
    "else:\n",
    "    print(\"Interaction Effect is not statistically significant.\")\n",
    "\n",
    "print(\"F-statistic for Software:\", main_effect_Software)\n",
    "print(\"F-statistic for Experience:\", main_effect_Experience)\n",
    "print(\"F-statistic for Interaction:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4aeac1-ce30-4878-a276-88b66ff95247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01af16cf-728e-4aec-9fd0-208daa6a7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two-sample t-test is statistically significant.\n",
      "t-statistic: -7.226469885613068\n",
      "p-value: 3.308588793249221e-09\n",
      "There is a statistically significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for control group and experimental group\n",
    "control_group = np.array([80, 85, 90, 78, 87, 82, 79, 88, 83, 81, 86, 84, 80, 89, 85, 82, 79, 87, 83, 81, 86, 84, 80, 89, 85])\n",
    "experimental_group = np.array([85, 92, 88, 93, 90, 87, 92, 89, 95, 91, 86, 94, 88, 93, 90, 87, 92, 89, 95, 91, 86, 94, 88, 93, 90])\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The two-sample t-test is statistically significant.\")\n",
    "    print(\"t-statistic:\", t_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is a statistically significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The two-sample t-test is not statistically significant.\")\n",
    "    print(\"t-statistic:\", t_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is no statistically significant difference in test scores between the groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075dfd6-9203-4676-99bb-0221e214d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e31292-55e6-4911-9ac6-16d81c60f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one-way ANOVA is statistically significant.\n",
      "F-statistic: 117.6847531395929\n",
      "p-value: 1.801733218371511e-25\n",
      "There is a statistically significant difference in daily sales between the three stores.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for daily sales for Store A, Store B, and Store C\n",
    "store_a_sales = np.array([100, 110, 120, 105, 115, 125, 110, 105, 115, 120, 130, 110, 115, 105, 120, 125, 110, 105, 115, 120, 100, 105, 115, 120, 105, 110, 115, 125, 110, 105])\n",
    "store_b_sales = np.array([90, 95, 100, 92, 98, 105, 92, 90, 100, 98, 110, 92, 95, 90, 100, 105, 92, 90, 100, 98, 92, 95, 100, 90, 105, 98, 95, 100, 105, 92])\n",
    "store_c_sales = np.array([80, 85, 92, 82, 88, 95, 85, 80, 92, 88, 100, 82, 85, 80, 92, 95, 82, 85, 95, 88, 82, 85, 92, 80, 95, 88, 85, 92, 95, 82])\n",
    "\n",
    "# Perform a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is a statistically significant difference in daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    print(\"There is no statistically significant difference in daily sales between the stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48cb77-b534-4cc1-8f25-60ed5b59dc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a054da2-a2a2-4a56-8ebb-4dfe5c104dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd0e16-5d36-45c8-8cea-b2eb40c435d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af3996-fb40-4129-b5b0-d5418c80749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847c1d4-d5a4-4ae4-b298-24533c384b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
